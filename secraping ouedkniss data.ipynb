{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Goal From This Notebook is :\n",
    "## Secraping All The Content Of Ouedkniss Website \n",
    "## (TOP 1 WEBSITE IN ALGERIA) \n",
    "\n",
    "###  1.first we need to explain how this website is orgnized :\n",
    "##### ouedkniss is a simple ads website , Where you can put your ad ,  It can be a product or a service \n",
    "##### the same idea existing in (Facebook's market place) .\n",
    "##### The Architecture of this website is as follows :\n",
    "##### the website is consist of stores and every store has an id and pages, the id in ouedknis is defined as an integer number , and id's start from 1 and growing sequencially (store 1 :has id=1 ,store 2 : has id=2 ...and so on ), the same thing for pages because (every page contain a limit of ads to see more ads you need to go to the next page (id=1&p=1,id=1&p=2 ... and so on) .\n",
    "##### exp : https://www.ouedkniss.com/store/?id=12085&p=2\n",
    "##### Then every store has a bunch of ads , ads are defined by a unique number and a unique link .\n",
    "##### exp : (ads number = 20621753 , ads link = https://www.ouedkniss.com/acer-spin314-i3-6006u-alger-bir-mourad-rais-algerie-informatique-d20621753 ) \n",
    "### 2.How we will secrabe all the data of the website \n",
    "##### huum , very easy actually ,We need to loop throgh the stores and in each store we need to get all the ads link \n",
    "##### then save the all the data od the ads \n",
    "##### this was a general overview of what we will do , you can understand it in detailed way in the code \n",
    "#### So i Would just say Happy Secraping ! , And let's start *-* .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Importing the necessary libraries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import requests \n",
    "from bs4 import BeautifulSoup as bs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) start secraping  nad get all the ads of ouedkniss ;) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ads=[] # we will append all the items of one ad to this list \n",
    "\n",
    "\n",
    "for i in range(1,50) : # there is apromixmatly 16000 store ,so we need to loop through all the stores ,this number is chnging by time\n",
    " prem = True # this is a trick variable we will use it to terminate the loop , you will see it later \n",
    " pagenumber = 1 # every store has a bunch of pages and every page have a bunch of ads ,and page's index start from 1\n",
    "\n",
    " while prem == True : # looping while prem = true\n",
    "   \n",
    "  store_id=i # i is a store id ofcourse as we describe above  \n",
    "  \n",
    "  # this 3 lines of print is to just help you to know in which store and wchich page you reach\n",
    "  print('store id :',store_id)\n",
    "  print('page number :',pagenumber)\n",
    "  print('--------------')\n",
    "\n",
    "  # get the link of the store with id = store_id and page = pagenumber\n",
    "  \n",
    "  url =\"https://www.ouedkniss.com/store/?id=\"+str(store_id)+\"&p=\"+str(pagenumber)\n",
    "  \n",
    "  page = requests.get(url) # we get the page with the help of requests library\n",
    "  \n",
    "  pagenumber =pagenumber+1  #inccrement the page number for the next iteration\n",
    "    \n",
    "  page = bs(page.content,features=\"html.parser\") # get the page content with the help of BeautifulSoup library\n",
    "\n",
    "  #  the Print out our page html prettify()\n",
    "  page.prettify()\n",
    "  \n",
    "  #now we have the html of the store = i and the page = pagenumber \n",
    "  \n",
    "  #the  store ads are all inside a div called  annonces\n",
    "  announces = page.find(id=\"annonces\") #we get the div annonces by its id \n",
    " \n",
    "  if announces == None : #somtimes there are stores without any ads so we will not find the announce div  \n",
    "     continue  # so if the store is empty we will move to another store \n",
    "  \n",
    "  #inside the div announce we have all the ads of the store\n",
    "  # and each ad is a 'ul'  \n",
    "  listOfads = announces.find_all('ul') #so we need to find all the 'ul' inside the announce div\n",
    "  \n",
    "  # Now we have all the ads of the dive announce of the store = i and page = pagenumber\n",
    "  \n",
    "  if listOfads == [] :# somtimes we have an announce div but empty and consist of 0 ads ,so we need to move to another store \n",
    "    prem = False # this equavalent to => break the loop while \n",
    "  \n",
    "  \n",
    "  for item in listOfads : #now we need to loop through all the ads and get thier caractiristic\n",
    "    \n",
    "   # each item is an ad and each ad contain a link \n",
    "\n",
    "   ad = [] \n",
    "   link = item.find('a') # so we rceive the link of the ad the links are without https://www.ouedkniss.com/\n",
    "   link = \"https://www.ouedkniss.com/\"+str(link['href']) # so we need to add it ,then we have the full link :)\n",
    "   print(link) #prints are just to for debuging purposes \n",
    "   \n",
    "   #now we have the link of the ads and we need to recieve it  \n",
    "   page = requests.get(\"https://www.ouedkniss.com/\"+str(link)) #recieve the page of the ad  \n",
    "   page = bs(page.content,features=\"html.parser\")\n",
    "   page.prettify()\n",
    "   \n",
    "   #after reciving our ad's html we start storing all the information of the ad\n",
    "    \n",
    "   # 1 . storing store id into the ad list\n",
    "   if store_id == None :\n",
    "    ad.append('store_id')\n",
    "    ad.append(None)\n",
    "   else :\n",
    "    ad.append('store_id')\n",
    "    ad.append(store_id)\n",
    "  \n",
    "   \n",
    "   # 2 . storing the category of the ad  \n",
    "   navigation = page.find(id=\"navigation\")\n",
    "   if navigation == None :\n",
    "     ad.append('category')\n",
    "     ad.append(None)\n",
    "   else: \n",
    "    category = navigation.find('a')\n",
    "    if category == None :\n",
    "     ad.append('category')\n",
    "     ad.append(None)\n",
    "    else :\n",
    "     ad.append('category') \n",
    "     ad.append(category.text)\n",
    "\n",
    "   #get the announce div of the ad wchich contain the information of the ad\n",
    "   announce = page.find('div',id=\"annonce\")\n",
    "   if announce == None :\n",
    "     continue\n",
    "        \n",
    "   # 3 . storing the ad title\n",
    "   ad_title = announce.find('h1',id=\"Title\")\n",
    "   \n",
    "   if ad_title == None :\n",
    "    ad.append('ad_title')\n",
    "    ad.append(None)\n",
    "   else :\n",
    "    ad.append('ad_title')\n",
    "    ad.append(product_title.text)\n",
    "\n",
    "  \n",
    "   # 3 . storing the ad price , ad_price mean the price of the service or the product in the ad\n",
    "   ad_price = announce.find('div',id=\"espace_prix\")\n",
    "   if ad_price == None :\n",
    "    ad.append('ad_price')    \n",
    "    ad.append(None)\n",
    "   else :\n",
    "\n",
    "    ad_price = ad_price.find('span',itemprop=\"price\")\n",
    "    ad.append('ad_price')\n",
    "    ad.append(ad_price.text)\n",
    "   \n",
    "   # ad number and publishing date ,number of viewers are all in the div Description\n",
    "   description = announce.find('div',id='Description')\n",
    "   \n",
    "  \n",
    "   # so we need to loop throgh all data in the descriptin div and store the following :\n",
    "   # 4. ad number\n",
    "   # 5. ad number of viwes\n",
    "   # 6. ad pusblishing date and hour \n",
    "\n",
    "   # you can just check  the inspect element of the description div and the following code will be clear \n",
    "   for data in description.find_all('p'):\n",
    "\n",
    "\n",
    "     label=data.find('label')\n",
    "     if label ==None :\n",
    "        label = None\n",
    "     else :\n",
    "       ad.append(label.get_text()) \n",
    "\n",
    "     span = data.find('span')\n",
    "\n",
    "     if span == None :\n",
    "       span = None\n",
    "     else :  \n",
    "      ad.append(span.get_text())  \n",
    "     \n",
    "     \n",
    "     \n",
    "  \n",
    "   # get the adress of the advertiser \n",
    "    \n",
    "   advertiser = announce.find('div',id='Annonceur')\n",
    "   if advertiser == None :\n",
    "    ad.append(None)\n",
    "   \n",
    "   advertiseradresse = advertiser.find('p').get_text()\n",
    "    \n",
    "   if advertiseradresse == None :\n",
    "    ad.append(None)\n",
    "   else : \n",
    "    ad.append('store_adress')\n",
    "    ad.append(advertiseradresse)\n",
    "   \n",
    "   #now we have all the items of the ad \n",
    "    \n",
    "   #prints always for debuging and checking the progress of the work  \n",
    "   print('------') \n",
    "   print(annonceuradresse)\n",
    "   print('------')\n",
    "    \n",
    "   #when we finished every ad we need to store it in the all_ads list\n",
    "   all_ads.append(ad)\n",
    "    \n",
    "   # then convert it to a pandas data frame  \n",
    "   pdd=pd.DataFrame(all_ads)\n",
    "   \n",
    "   #and store it in a csv file \n",
    "   pdd.to_csv('all_ouedkniss_ads.csv')\n",
    "   \n",
    "\n",
    "  \n",
    "\n",
    "   \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Amazing step , we have now collect all the ads of ouedkniss website \n",
    "##### the code above take me about 48 hours to fetch all tha data of the website (my laptop : i5 6300U ,8 giga RAM DDR4)\n",
    "##### after that we need to clean our data .\n",
    "\n",
    "#### c) clean our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read our dataset\n",
    "dataset=pd.read_csv('all_ouedkniss_ads.csv',sep='delimiter',header=None)\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrows = [] #we will store our clean date in the allrows list \n",
    "\n",
    "i=0\n",
    "\n",
    "while i < dataset.count()[0] : #looping through all the rows of our dataset\n",
    "    print('-----')\n",
    "    print(i)\n",
    "    print('-----')\n",
    "    clean_ad = [] #we will put the cleaning items of the ad in clean_ad\n",
    "    \n",
    "    # what we will do now is simple \n",
    "    \n",
    "    #our data  for the first data set is as following :\n",
    "    #'store_id',1,'category','informatics',....\n",
    "    \n",
    "    # we need to convert it to the following :\n",
    "    \n",
    "    #'store_id','category'\n",
    "    #   1      , 'informatic'\n",
    "    \n",
    "    # and also deleting rows with nan values or wrong type of values \n",
    "    # and changing format of some rows \n",
    "    # and other things ,follow the code to undestand the rest \n",
    "    # lets do it \n",
    "    \n",
    "    #recive the row i and split it by \",\"\n",
    "    value  = dataset.iloc[i].values[0].split(\",\")\n",
    "    #print(value)\n",
    "    \n",
    "    # 1. get store id \n",
    "    try : \n",
    "\n",
    "     index = value.index('store_id')\n",
    "     clean_ad.append(int(value[index+1]))\n",
    "    except ValueError : \n",
    "       clean_ad.append(None)     \n",
    "    \n",
    "    # 2. get category \n",
    "    \n",
    "    try :\n",
    "        index = value.index('category')\n",
    "        clean_ad.append(value[index+1])\n",
    "    except ValueError : \n",
    "         clean_ad.append(None)   \n",
    "\n",
    "    # 3. get product_title \n",
    "    try :\n",
    "\n",
    "        index = value.index('ad_title')\n",
    "        clean_ad.append(value[index+1])\n",
    "    except ValueError : \n",
    "        clean_ad.append(None)\n",
    "\n",
    "    # 4. get the ad_price \n",
    "    try :\n",
    "\n",
    "        price  = value[8].split()\n",
    "    except ValueError : \n",
    "        price = None\n",
    "    # we need to correct also the format of the price \n",
    "    # for exp 1 million should be 10000 and the unit is DZD ..etc\n",
    "    #if price!=None :\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(price)>=2 :\n",
    "        \n",
    "        if price[1] == 'Millions'  :\n",
    "            price[0] = float(price[0]) * 10000\n",
    "    \n",
    "        elif price[1] == 'Milliardss' :\n",
    "            price[0] = float(price[0]) * 10000000\n",
    "     \n",
    "    if price == [] :\n",
    "        clean_ad.append(None)     \n",
    "    else :\n",
    "        clean_ad.append(price[0])  \n",
    "\n",
    "    # 5. get the ad's number\n",
    "    \n",
    "    # when we fetch our data somtimes parsing errors occur\n",
    "    # for example instead of reciveing the value 'Numéro' we recieve 'NumÃ©ro : ' \n",
    "    # so atrrubutes list contain all the written posibilities of the value  in our dataset\n",
    "    \n",
    "    attrubutes = ['Numéro : ','NumÃ©ro : ','NumÃƒÂ©ro : '] \n",
    "    for atr in attrubutes :\n",
    "        try :\n",
    "         index = value.index(atr)\n",
    "         clean_ad.append(int(value[index+1]))\n",
    "        except ValueError :\n",
    "            continue\n",
    "        else : \n",
    "            break\n",
    "            \n",
    "    \n",
    "\n",
    "    # 6. get the ad's views \n",
    "    \n",
    "    try :\n",
    "     index = value.index('Nombre de vues : ')\n",
    "     clean_ad.append(int(value[index+1]))\n",
    "    except ValueError :\n",
    "        clean_ad.append(None)\n",
    "        \n",
    "\n",
    "    # 7. get publishing date \n",
    "    \n",
    "    attrubutes = ['DÃ©posÃ©e le : ','Déposée le : ']\n",
    "    j=0\n",
    "    for atr in attrubutes :\n",
    "            j=j+1\n",
    "            try :\n",
    "                index = value.index(atr)\n",
    "                pdate = value[index+1]\n",
    "                print(pdate)\n",
    "                clean_ad.append(pdate)\n",
    "            except ValueError :\n",
    "               \n",
    "               if j == len(attrubutes):\n",
    "                   clean_ad.append(None)\n",
    "                   break\n",
    "            \n",
    "\n",
    "    # 8. get the store adress\n",
    "    \n",
    "    try :\n",
    "     index = value.index('store_adress')\n",
    "     adr = value[index+1].split(\" \",1)\n",
    "     clean_ad.append(adr[0])\n",
    "    except  ValueError : \n",
    "       clean_ad.append(None)\n",
    "    \n",
    "\n",
    "    # increment to the next row\n",
    "    i=i+1\n",
    "    \n",
    "    #append our preprocessed ad (clean_ad) to allrows list\n",
    "    \n",
    "    allrows.append(clean_ad)\n",
    "# now we have all the preprocessed ads in the allrows list \n",
    "#lets change it to a pandas data frame\n",
    "dataset = pd.DataFrame(allrows)\n",
    "dataset.to_csv('cleandata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the final touch \n",
    "dataset = pd.read_csv('cleandata.csv')\n",
    "\n",
    "\n",
    "# we need to drop the 2 following column \n",
    "dataset = dataset.drop('Unnamed: 0',axis=1)\n",
    "dataset = dataset.drop('7',axis=1)\n",
    "\n",
    "# define the header of our dataset\n",
    "header = ['store_id','category','product_title','ad_price','ad_number','ad_views','publishing_date','store_adress']\n",
    "\n",
    "#affecr the header to the dataset\n",
    "dataset.columns = header \n",
    "\n",
    "#delete all rows with nan values \n",
    "dataset=dataset.dropna(axis=0)\n",
    "\n",
    "#ensure that all the values of column 'ad_price' is float , else delete the row  \n",
    "dataset['ad_price'] = dataset['ad_price'].apply(pd.to_numeric ,errors='coerce').fillna(0).astype(float).dropna()\n",
    "\n",
    "#finally exporting te finall version \n",
    "dataset.to_csv('ouedknisFinallVersion.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
